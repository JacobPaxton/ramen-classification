{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987981ee",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook explores the cleaned ramen-ratings CSV. Any engineered features or scripts will be added to explore.py.\n",
    "\n",
    "# Findings\n",
    "1. Ramen packaging and five-star ratings are independent.\n",
    "2. Ramen country of origin and five-star ratings **have a dependent relationship.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d27764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2021de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (1515, 5) Validate size: (506, 5) Test size: (506, 5)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1515 entries, 2566 to 2127\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   brand       1515 non-null   object\n",
      " 1   name        1515 non-null   object\n",
      " 2   package     1515 non-null   object\n",
      " 3   country     1515 non-null   object\n",
      " 4   five_stars  1515 non-null   bool  \n",
      "dtypes: bool(1), object(4)\n",
      "memory usage: 60.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# create train split for exploration\n",
    "train, _, _ = wrangle.prep_explore()\n",
    "print('')\n",
    "\n",
    "# check work\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc145762",
   "metadata": {},
   "source": [
    "# Initial Exploration of Ramen Packaging\n",
    "Let's check if there's a dependent relationship between packaging and our target.\n",
    "\n",
    "Hypotheses:\n",
    "- $H_0$: Packaging and five-star ratings are independent.\n",
    "- $H_a$: Packaging and five-star ratings have a dependent relationship.\n",
    "\n",
    "Confidence interval: 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd793f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set confidence interval\n",
    "alpha = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "121014e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dependence of packaging and target\n",
    "package_5star_crosstab = pd.crosstab(train.package, train.five_stars)\n",
    "_, p, _, _ = stats.chi2_contingency(package_5star_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "771e5b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packaging and five-star ratings are independent, did not pass 95% confidence interval.\n",
      "p-value: 0.43924606238117814\n"
     ]
    }
   ],
   "source": [
    "# check if p is significant\n",
    "if p < alpha:\n",
    "    print(\"Packaging and five-star ratings have a dependent relationship with 95% confidence.\")\n",
    "    print(\"p-value:\", p)\n",
    "else:\n",
    "    print(\"Packaging and five-star ratings are independent, did not pass 95% confidence interval.\")\n",
    "    print(\"p-value:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173e8e31",
   "metadata": {},
   "source": [
    "**Packaging and five-star ratings are independent.** We will not use 'package' in our predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021715d4",
   "metadata": {},
   "source": [
    "# Initial Exploration of Ramen Country of Origin\n",
    "Let's check if there's a dependent relationship between country and our target.\n",
    "\n",
    "Hypotheses:\n",
    "- $H_0$: Country of origin and five-star ratings are independent.\n",
    "- $H_a$: Country of origin and five-star ratings have a dependent relationship.\n",
    "\n",
    "Confidence interval: 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "854971c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set confidence interval\n",
    "alpha = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b738143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create crosstab for chi-square statistical test\n",
    "country_5star_crosstab = pd.crosstab(train.country, train.five_stars)\n",
    "# limit only to countries with sufficient value counts in crosstab (an assumption of chi-square)\n",
    "enough_values_mask = (country_5star_crosstab[False] > 5) & (country_5star_crosstab[True] > 5)\n",
    "# run chi-square test\n",
    "_, p, _, _ = stats.chi2_contingency(country_5star_crosstab[enough_values_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c0983b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country of origin and five-star ratings have a dependent relationship with 95% confidence.\n",
      "p-value: 1.680501270556502e-06\n"
     ]
    }
   ],
   "source": [
    "# check if p is significant\n",
    "if p < alpha:\n",
    "    print(\"Country of origin and five-star ratings have a dependent relationship with 95% confidence.\")\n",
    "    print(\"p-value:\", p)\n",
    "else:\n",
    "    print(\"Country of origin and five-star ratings are independent, did not pass 95% confidence interval.\")\n",
    "    print(\"p-value:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8864998",
   "metadata": {},
   "source": [
    "**Country of origin and five-star ratings have a dependent relationship.** We will further explore country of origin and consider using it in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c473b",
   "metadata": {},
   "source": [
    "# Initial Exploration of Ramen Brand\n",
    "Let's check if there's a dependent relationship between ramen brand and our target.\n",
    "\n",
    "Hypotheses:\n",
    "- $H_0$: Ramen brand and five-star ratings are independent.\n",
    "- $H_a$: Ramen brand and five-star ratings have a dependent relationship.\n",
    "\n",
    "Confidence interval: 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aababe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set confidence interval\n",
    "alpha = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25fe82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create crosstab for chi-square statistical test\n",
    "brand_5star_crosstab = pd.crosstab(train.brand, train.five_stars)\n",
    "# limit only to brands with sufficient value counts in crosstab (an assumption of chi-square)\n",
    "enough_values_mask = (brand_5star_crosstab[False] > 5) & (brand_5star_crosstab[True] > 5)\n",
    "# run chi-square test\n",
    "_, p, _, _ = stats.chi2_contingency(brand_5star_crosstab[enough_values_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d70b87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramen brand and five-star ratings are independent, did not pass 95% confidence interval.\n",
      "p-value: 0.22292206264805428\n"
     ]
    }
   ],
   "source": [
    "# check if p is significant\n",
    "if p < alpha:\n",
    "    print(\"Ramen brand and five-star ratings have a dependent relationship with 95% confidence.\")\n",
    "    print(\"p-value:\", p)\n",
    "else:\n",
    "    print(\"Ramen brand and five-star ratings are independent, did not pass 95% confidence interval.\")\n",
    "    print(\"p-value:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11480ff7",
   "metadata": {},
   "source": [
    "**Ramen brand and five-star ratings are independent.** We will not use 'brand' in our predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e15c104",
   "metadata": {},
   "source": [
    "# Breaking Down the Ramen Product Name\n",
    "Nearly all ramen reviews in our dataset have a unique combination of brand and product name. Only 21 combinations of brand and product out of the nearly 1500 in our exploration split have two reviews, and there are no combinations with more than two reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c6877f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand+name with only one review: 1473\n",
      "Brand+name with two reviews: 21\n",
      "Brand+name with more than two reviews: 0\n"
     ]
    }
   ],
   "source": [
    "# show the review repeats and non-repeats\n",
    "print(\"Brand+name with only one review:\", (train[['brand','name']].value_counts() == 1).sum())\n",
    "print(\"Brand+name with two reviews:\", (train[['brand','name']].value_counts() == 2).sum())\n",
    "print(\"Brand+name with more than two reviews:\", (train[['brand','name']].value_counts() > 2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604c51c",
   "metadata": {},
   "source": [
    "Because of this, we will need to split out certain keywords in product names to use as features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc8e21d",
   "metadata": {},
   "source": [
    "## Identifying Keywords to Use\n",
    "I looked at ramen with the word 'flavor' in the title in my older analysis. These are the counts I found:\n",
    "- Chicken (48); Beef (30); Pork (16); Shrimp (12); Fish/Seafood (10); Chow Mein (6);\n",
    "- Chili/Chilli (7); Curry (6); Kimchi (5); Stir-Fry (4);\n",
    "- Tom Yum (6); Tonkotsu (5); Miso (4); Wonton (2); Jjamppong (1); Shiodare (1); Bulgogi (1); Bulalo (1);\n",
    "- Tomato (6); Mushroom (5); Sesame (5); Onion (3); Shiitake (1);\n",
    "- Spicy (26); Hot (12); Soy (6); Sour (6); Sweet (2); Umami [savory] (2);\n",
    "- Sriracha (3); \n",
    "- Abalone (4);\n",
    "- Vegetable (11);\n",
    "- has_Lime (8);\n",
    "\n",
    "I will use these words to search the train split for more potential keywords. The words I find interesting will all be listed here:\n",
    "- Instant or Minute (does the name indicate a worse rating?)\n",
    "- Artificial or Imitation (do artificial products rate worse than others?)\n",
    "- Stew (do stews outperform other styles of ramen?)\n",
    "- Good or Premium or Delicious (does the name indicate a better rating?)\n",
    "- Less Sodium (does less sodium make for a worse-rated product?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c267a99f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chicken                                                        5\n",
       "Instant Noodles Chicken Flavour                                4\n",
       "Artificial Chicken                                             3\n",
       "Chicken Abalone Flavour                                        2\n",
       "Imitation Chicken Vegetarian                                   2\n",
       "Chicken Flavor                                                 2\n",
       "Artificial Chicken Rice Vermicelli                             1\n",
       "Good Chicken Bean Vermicelli                                   1\n",
       "Pan Asian Kitchen Sweet & Sour Chicken Flavor Ramen Noodles    1\n",
       "Spoon-it Creamy Chicken                                        1\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chicken (highest word count in previous analysis)\n",
    "train[train.name.str.contains('Chicken')].name.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3d42c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Beef                                            5\n",
       "Artificial Spicy Beef                           3\n",
       "Artificial Stew Beef                            2\n",
       "Premium Instant Noodles Roasted Beef Flavour    2\n",
       "Kung Fu Artificial Beef Rice Noodle             2\n",
       "Instant Noodles Beef Flavour                    2\n",
       "Hot & Sour Beef Noodles                         2\n",
       "Hot & Spicy Beef                                2\n",
       "Artificial Beef Flavor                          2\n",
       "Beef Tongue Shio Mayo Ramen                     1\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beef (second highest word count in previous analysis)\n",
    "train[train.name.str.contains('Beef')].name.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f81af98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artificial Spicy Beef                                                    3\n",
       "Sichuan Spicy Flavor                                                     2\n",
       "Hot & Spicy Beef                                                         2\n",
       "Chongqing Spicy Hot Noodles                                              1\n",
       "Whatâ€™s That? Leisure Meatballs Spicy Chicken Flavor                      1\n",
       "Nature Is Delicious Spicy                                                1\n",
       "Bowl Noodles Hot & Spicy Chicken Flavor Less Sodium Ramen Noodle Soup    1\n",
       "Spicy Shrimp Cup Noodle                                                  1\n",
       "2 Minute Noodles Hungrooo Masala Spicy                                   1\n",
       "Guanmiao Dried Noodles With Spicy Sauce                                  1\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spicy (third highest word count in previous analysis)\n",
    "train[train.name.str.contains('Spicy')].name.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d49421d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

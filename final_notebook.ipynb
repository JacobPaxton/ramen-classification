{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2810aa0",
   "metadata": {},
   "source": [
    "# <center>Overview\n",
    "This project analyzes the Ramen Ratings dataset from Kaggle. This dataset has a few thousand ramen products and their ratings, from 0 to 5 stars. The data includes the review number, the ramen's brand, product name, packaging style, country of origin, rating, and whether or not the ramen is in the top 10. I chose to make this a one-vs-rest classification problem on whether a ramen is rated five stars or not. The analysis uses independence tests and feature engineering to arrive at key drivers of five-star ratings, then uses these features to build a predictive model. The project successfully identified key drivers using these methods and build a predictive model that performs better than a standard baseline for the work.\n",
    "\n",
    "## The cool new stuff I accomplished for this project\n",
    "- **Heavy keyword engineering**\n",
    "    * Domain research to understand ramen products based on keyword\n",
    "    * Translation to group all keywords into consistent categories\n",
    "    * Categorization on common factors based on domain research and translation\n",
    "- **Multi-layered statistical testing to eliminate features**\n",
    "    * Chi-Square tests to eliminate initial features that are not related to target\n",
    "    * One-hot encoding of remaining features' categories\n",
    "    * Chi-Square tests to eliminate one-hot-encoded categories that are not related to target\n",
    "- **Clustering country and keyword features into low-, medium-, and high-rate five-star ratings groups**\n",
    "    * Checked proportions of five-star rating counts against not-five-star rating counts for True in encoded feature\n",
    "    * Checked proportions of five-star rating counts against not-five-star rating counts for False in encoded feature\n",
    "    * Compared five-star proportions to check increase/decrease in proportion from False to True\n",
    "    * Bracketed increasing, middle, and decreasing proportions from False to True\n",
    "    \n",
    "## Other stuff that I've done before\n",
    "- Wrangle\n",
    "    * Categorize and encode target into five_stars column (classes: is five-stars, isn't five stars)\n",
    "    * Fix some values, drop some nulls, outliers, and duplicate rows, get rid of unnecessary columns\n",
    "    * Create univariate visualizations\n",
    "- Explore\n",
    "    * Run Chi-Square testing to determine if feature is related to target\n",
    "    * Feature engineering (overall)\n",
    "    * Create bivariate visualizations\n",
    "    * Choose features for model\n",
    "- Model\n",
    "    * Choose optimization priorities for the model (F1 Score)\n",
    "    * Resample the target to address class imbalance\n",
    "    * Create baseline model and multiple algorithmic models with varying hyperparameter combinations\n",
    "    * Evaluate models on Validate (first out-of-sample split)\n",
    "    * Choose best model in terms of our optimization priority\n",
    "    * Calculate ROC AUC of baseline and best model\n",
    "    * Evaluate baseline and best model on Test split\n",
    "    \n",
    "## Findings\n",
    "1. The brand of ramen does not influence whether or not the ramen product has a five-star rating.\n",
    "1. The packaging of ramen does not influence whether or not the ramen product has a five-star rating.\n",
    "1. A ramen's country of origin has an influence on whether or not the ramen product has a five-star rating.\n",
    "    - Malaysia has the highest five-star rating proportion of all origin countries.\n",
    "    - Ramen originating from Malaysia, Singapore, or Taiwan have the highest proportion of five-star ratings.\n",
    "    - Ramen from Hong Kong, Japan, South Korea, or Indonesia have the next-highest proportions of five-star ratings.\n",
    "    - Ramen from China, Thailand, or USA have the lowest proportions of five-star ratings.\n",
    "    - China has the lowest five-star rating proportion of all origin countries.\n",
    "1. A ramen's noodle type does not influence whether or not the ramen product has a five-star rating.\n",
    "1. A ramen's flavor influences whether or not the ramen product has a five-star rating.\n",
    "    - Curry flavor has the highest proportion of five-star ratings for all flavor categories.\n",
    "    - Ramen with curry or sesame flavor have the highest proportions of five-star ratings.\n",
    "    - Ramen with pork flavor or the common crustaceans have the next-highest proportions of five-star ratings.\n",
    "    - Chicken- and beef- flavored ramen products have the lowest five-star rating proportions of all flavors.\n",
    "    - Chicken flavor has the lowest five-star rating proportions of all flavors.\n",
    "1. A ramen's spicy status influences whether or not the ramen product has a five-star rating.\n",
    "1. A ramen's fried status does not have an effect on whether or not the ramen product has a five-star rating.\n",
    "\n",
    "## Model Results\n",
    "- Features used: country and flavor brackets (as described above) and spicy status\n",
    "- Evaluation Metric: F1 Score\n",
    "- Best model: Logistic Regression\n",
    "- Model performance: outperforms the baseline on F1 Score and ROC AUC for unseen data\n",
    "\n",
    "# <center>Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f5c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "import wrangle\n",
    "import explore\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc2601",
   "metadata": {},
   "source": [
    "# <center>Wrangle\n",
    "## Bottom Line Up Front: What I Did for Wrangle\n",
    "1. Acquire ramen-ratings.csv from Kaggle\n",
    "1. Rename a United States value to USA\n",
    "1. Drop low-count ramen styles Box, Can, and Bar (8 rows)\n",
    "1. Drop countries with less than 5 cumulative observations (29 rows)\n",
    "1. Drop Unrated, nulls and duplicates (16 rows)\n",
    "1. Replace Stars column with five_stars column\n",
    "1. Drop 'Review #' and 'Top Ten' columns\n",
    "1. Rename columns for easier exploration\n",
    "1. Split cleaned data into Train, Validate, and Test splits for exploration and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16a1810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (1515, 5) Validate size: (506, 5) Test size: (506, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>package</th>\n",
       "      <th>country</th>\n",
       "      <th>five_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>Samyang</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Pack</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Nongshim</td>\n",
       "      <td>Shin Noodle Soup</td>\n",
       "      <td>Cup</td>\n",
       "      <td>USA</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>Doll</td>\n",
       "      <td>Hello Kitty Dim Sum Noodle Japanese Curry Flavour</td>\n",
       "      <td>Cup</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         brand                                               name package  \\\n",
       "2566   Samyang                                                Hot    Pack   \n",
       "332   Nongshim                                   Shin Noodle Soup     Cup   \n",
       "1363      Doll  Hello Kitty Dim Sum Noodle Japanese Curry Flavour     Cup   \n",
       "\n",
       "          country  five_stars  \n",
       "2566  South Korea       False  \n",
       "332           USA        True  \n",
       "1363    Hong Kong       False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrangle.py script to wrangle the data as described above\n",
    "train, _, _ = wrangle.prep_explore()\n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8db2107",
   "metadata": {},
   "source": [
    "# <center>Explore\n",
    "## Bottom Line Up Front: What I Did for Explore\n",
    "- Statistical testing on Ramen Brands that found brand is independent of five-star outcomes\n",
    "- Statistical testing on Ramen Packaging that found packaging is independent of five-star outcomes\n",
    "- Statistical testing on Country of Origin that found country is related to five-star outcomes\n",
    "- Keyword engineering to categorize ramen products into noodle type, flavor, spicy status, and fried status categories\n",
    "- Statistical testing on new features that found noodle type and fried status have no impact on five-star outcomes\n",
    "- Statistical testing on new features that found ramen flavor and spicy status have an impact on five-star outcomes\n",
    "- Dropped specific countries and flavors that did not have at least 5 reviews with five-star rating\n",
    "- Analyzed proportions of five-star reviews to all reviews for each country and flavor category\n",
    "- Grouped into high-, medium-, and low-proportion brackets for country and for flavor category\n",
    "- Checked country and flavor category brackets along with spicy status in terms of five-star and non-five-star reviews\n",
    "- Chose these features for modeling\n",
    "\n",
    "## Ramen Brand is Independent\n",
    "- $H_0$: Ramen brand and five-star ratings are independent.\n",
    "- $H_a$: Ramen brand and five-star ratings have a dependent relationship.\n",
    "\n",
    "Confidence interval: 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abbc54a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramen brand and five-star ratings are independent, did not pass 95% confidence interval.\n",
      "p-value: 0.223\n"
     ]
    }
   ],
   "source": [
    "# run chi-square test on ramen brand\n",
    "explore.chi2_ramen_brand(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db0f263",
   "metadata": {},
   "source": [
    "## Ramen Packaging is Independent\n",
    "\n",
    "- $H_0$: Packaging and five-star ratings are independent.\n",
    "- $H_a$: Packaging and five-star ratings have a dependent relationship.\n",
    "\n",
    "Confidence interval: 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "823e2af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packaging and five-star ratings are independent, did not pass 95% confidence interval.\n",
      "p-value: 0.439\n"
     ]
    }
   ],
   "source": [
    "# run chi-square test on ramen packaging\n",
    "explore.chi2_ramen_packaging(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640a412b",
   "metadata": {},
   "source": [
    "## Ramen Country of Origin is Related\n",
    "\n",
    "- $H_0$: Country of origin and five-star ratings are independent.\n",
    "- $H_a$: Country of origin and five-star ratings have a dependent relationship.\n",
    "\n",
    "Confidence interval: 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04d32a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country of origin and five-star ratings have a dependent relationship with 95% confidence.\n",
      "p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# run chi-square test on ramen country of origin\n",
    "explore.chi2_ramen_origin_country(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265025c",
   "metadata": {},
   "source": [
    "## Breaking Down the Ramen Product Name\n",
    "### Why We Needed to Engineer Features for Product Name\n",
    "Nearly all ramen reviews in our dataset have a unique combination of brand and product name. Only 21 combinations of brand and product out of the nearly 1500 in our exploration split have two reviews, and there are no combinations with more than two reviews. Because of this low commonality, we couldn't run initial chi-square tests to see if product names have a dependent relationship with five star reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd8cf4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand+name with only one review: 1473\n",
      "Brand+name with two reviews: 21\n",
      "Brand+name with more than two reviews: 0\n"
     ]
    }
   ],
   "source": [
    "# show the review repeats and non-repeats\n",
    "print(\"Brand+name with only one review:\", (train[['brand','name']].value_counts() == 1).sum())\n",
    "print(\"Brand+name with two reviews:\", (train[['brand','name']].value_counts() == 2).sum())\n",
    "print(\"Brand+name with more than two reviews:\", (train[['brand','name']].value_counts() > 2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88dbe8f",
   "metadata": {},
   "source": [
    "### Identifying Keywords\n",
    "I've designated certain keywords that I will use to categorize product names. Although that raw list is contained in the explore.py script, the analysis in this notebook will break it down into an organized format.\n",
    "\n",
    "Based on the designated keywords, I ran the following two cells to check remaining values that I missed earlier. If I found a notable word, I added it to the above keyword list and re-ran the cells. I repeated this process until I was satisfied with the words I had designated as keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5a1d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1377\n",
       "False     138\n",
       "Name: has_keyword, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create has_keyword column, check value counts\n",
    "explore.create_has_keyword(train).has_keyword.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ab8c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noodles    34\n",
      "Noodle     30\n",
      "Ramen      19\n",
      "Instant    16\n",
      "Cup        14\n",
      "Flavour    11\n",
      "Sauce      11\n",
      "Flavor     10\n",
      "Rasa        9\n",
      "Mi          8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check top-10 words\n",
    "explore.check_non_keywords(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a421ab",
   "metadata": {},
   "source": [
    "### Categorization Using Domain Research and Translation\n",
    "During and after creating this keyword list, I conducted background research and translation on keywords for the purposes of categorization. **This process took the most time of any step in this project.** \n",
    "\n",
    "I built the categories from scratch and researched whether a word indicated the product belonged to the category or not. After many iterations of this category creation and attribution, I came up with four features, which will be shown later. An early result of this process is contained here as an example.\n",
    "\n",
    "**Taste**\n",
    "* 'Spicy', 'Spice', 'Shin', 'Jjamppong'/'Jjambbong'(seafood), 'Buldalk'(chicken), 'Sutah'(beef), 'Budae'(sausage), 'Habanero', 'Jinjja', 'Jin', 'Yeul', 'Mala', 'Teumsae', 'Bibim', 'Picante', 'Bulnak', 'Volcano', 'Odongtong', 'Sriracha', 'Arrabiata', 'Tom Yum', 'Tom Yam', 'Tom Saab', 'Tom Klong', 'Suki', 'Laksa' (304)\n",
    "* 'Ramyonsari', 'Keopnurungji' (2)\n",
    "* 'Salt', 'Shio', 'Sio' (17)\n",
    "* 'Soy', 'Shoyu', 'Shouyu', 'Teriyaki' (70)\n",
    "* 'Mayo' (6)\n",
    "* 'Cheese' (11)\n",
    "* 'Sweet' (18)\n",
    "* 'Sour', 'sour' (19)\n",
    "* 'Curry' (68)\n",
    "* 'Sesame' (32)\n",
    "* 'Pickle' (11)\n",
    "* 'Masala' (9)\n",
    "\n",
    "As you can see, I grouped keywords loosely here and checked how many products contained at least one of the keywords in each bulletpoint. The code to check that number is shown below as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5cc332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking row count having the above noodle types (ran this cell multiple times with different inputs)\n",
    "train.name.str.contains(\"|\".join(['Soy', 'Shoyu', 'Shouyu', 'Teriyaki'])).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7bc38",
   "metadata": {},
   "source": [
    "### Choosing Candidate Features\n",
    "After creating these rough categories and checking row counts, we were able to begin considering what features we should use in our analysis. \n",
    "#### Requirements\n",
    "1. A feature must have at least two unique values \n",
    "    * EX: A 'meat_type' feature must have at least two categories, like 'chicken', 'beef', 'pork', etc\n",
    "1. Each unique value in the feature must have a count of at least 10\n",
    "    * Assumption of chi-square test: each crosstab cell must have at least a value of 5\n",
    "    * Anything less than 10, when split for the crosstab, will not meet this chi-square assumption\n",
    "    * EX: 'chicken' should have at least a count of 10\n",
    "1. The feature's values should be independent from one another \n",
    "    * EX: 'taste_type' should not have individual 'sweet' and 'sour' values because some ramen have 'sweet & sour' in the product name\n",
    "    \n",
    "#### Features that Pass the Above Requirements\n",
    "- noodle_type: \n",
    "    * **wheat** ('Udon', 'Udoin', 'U-Dong', 'U-dong', 'Sano', 'Spaghetti', 'Carbonara', 'Neapolitan', 'Napolitan', 'Kalguksoo') (63)\n",
    "    * **buckwheat** ('Buckwheat', 'Soba') (18)\n",
    "    * **rice** ('Rice', 'Vermicelli', 'Vernicalli', 'Bihun', 'Biryani', 'Tteokbokki', 'Tteobokki', 'Topokki', 'Rabokki') (109)\n",
    "- flavor: \n",
    "    * **miso** ('Miso') (23)\n",
    "    * **chicken** ('Chicken', 'Chikin', 'Duck', 'Pollo', 'Buldalk', 'Buldak', 'Requeijao', 'Gallina') (215)\n",
    "    * **beef** ('Beef', 'Gomtang', 'Seolleongtang', 'Sukiyaki', 'Nam Tok', 'Sutah', 'Sogokimyun', 'Cuchareable', 'Carne', 'Kebab', 'Gentong', 'Bulalo', 'Yukgaejang') (163)\n",
    "    * **pork** ('Pork', 'Prok', 'Jjajangmyeon', 'Jjajangmen', 'Jiajang', 'Jjajang', 'Chacharoni', 'Jjawang', 'Tonkotsu', 'Tomkotsu', 'Bacon', 'Ossyoi', 'Yakibuta', 'Batchoy') (115)\n",
    "    * **crustacean** ('Crab', 'Lobster', 'Shrimp', 'Prawn') (108)\n",
    "    * **mollusk** ('Bajirak', 'Clam', 'Abalone', 'Scallop', 'Vongole') (15)\n",
    "    * **chili** ('Chili', 'Chilli', 'chili', 'Cabe') (37)\n",
    "    * **curry** ('Curry', 'curry', 'Betawi', 'Perisa', 'Kari') (93)\n",
    "    * **chow_mein** ('Chow Mein') (25)\n",
    "    * **kimchi** ('Kimchi', 'Kimchee', 'Sabalmyeon', 'Kim Chee') (24)\n",
    "    * **mushroom** ('Mushroom', 'Shiitake', 'Shitake') (35)\n",
    "    * **tomato** ('Tomato') (21)\n",
    "    * **veggie** ('Clear', 'Veg', 'Oosterse') (86)\n",
    "    * **sesame** ('Sesame', 'Sesami') (33)\n",
    "    * **lime** ('Lime', 'Jeruk Nipis', 'Kalamansi') (11)\n",
    "- spicy:\n",
    "    * **True** ('Spicy', 'Spice', 'Shin', 'Jjamppong'/'Jjambbong'/'Jjampong'/'Champong'(seafood), 'Buldalk'/'Buldak'(chicken), 'Sutah'(beef), 'Budae'(sausage), 'RMy', 'Habanero', 'Jinjja', 'Jin', 'Yeul', 'Mala', 'Teumsae', 'Bibim', 'Picante', 'Bulnak', 'Volcano', 'Odongtong', 'Sriracha', 'Arrabiata', 'Tom Yum', 'Tom Yam', 'tom Yum', 'Tom Saab', 'Tom Klong', 'Suki', 'Laksa', 'Chah Chiang', 'Namja', 'Befikr', 'Mi Goreng', 'Kocek', 'Jalapeno', 'Pad Kee Mao', 'Kokomen', 'Wasabi', 'Kung Pao', 'Kimchi', 'Kimchee', 'Sabalmyeon', 'Kim Chee', 'Nam Tok', 'Sogokimyun', 'Gentong', 'Chili', 'Chilli', 'chili', 'Cabe', 'Yukgaejang', 'Yakisoba', 'Yaki-Soba', 'Yakiosoba') (446)\n",
    "    * **False** ('Miso', 'Requeijao', 'Seolleongtang', 'Sukiyaki', 'Jjajangmyeon', 'Jjajangmen', 'Jiajang', 'Jjajang', 'Chacharoni', 'Jjawang', 'Ossyoi', 'Batchoy', 'Bajirak', 'Mushroom', 'Shiitake', 'Shitake', 'Tomato', 'Clear') (99)\n",
    "- fried:\n",
    "    * **True** ('Stir Fry', 'Stir-Fried', ' Fried', 'Bokkeum', 'Tteokbokki', 'Tteobokki', 'Topokki', 'Yukgaejang', 'Rabokki', 'Yakisoba', 'Yaki-Soba', 'Yakiosoba', 'Goreng', 'Tempura', 'Kung Pao', 'Sukiyaki', 'Kebab', 'Gentong', 'Bulalo', 'Jjajangmyeon', 'Jjajangmen', 'Jiajang', 'Jjajang', 'Chacharoni', 'Jjawang', 'Tonkotsu', 'Tomkotsu', 'Bacon', 'Yakibuta', 'Batchoy', 'Chow Mein') (198)\n",
    "    * **False** ('Non-Fried', 'Requeijao', 'Yakisoba', 'Yaki-Soba', 'Yakiosoba', 'Gomtang', 'Seolleongtang', 'Nam Tok', 'Sutah', 'Sogokimyun', 'Cuchareable', 'Gomtang', 'Yukgaejang', 'Ossyoi', 'Clear') (52)\n",
    "    \n",
    "### Creating the Features, Testing for Relationship to Target\n",
    "After background research and translation, after several rounds of categorization, after restricting categories for testing, and after choosing features that will maintain independence between categories, we finally have something to work with. \n",
    "\n",
    "Now, we will create each feature as described above, then test each feature to see if they have a relationship with our target, five_stars.\n",
    "\n",
    "#### noodle_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed5e2a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noodle type and five-star ratings are independent, did not pass 95% confidence interval.\n",
      "p-value: 0.725\n"
     ]
    }
   ],
   "source": [
    "# create noodle_type feature\n",
    "train = explore.create_noodle_type(train)\n",
    "# test noodle_type for independence\n",
    "explore.chi2_ramen_noodle_type(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c61bc7",
   "metadata": {},
   "source": [
    "#### flavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c1eda96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flavor and five-star ratings have a dependent relationship with 95% confidence.\n",
      "p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# create flavor feature\n",
    "train = explore.create_flavor(train)\n",
    "# test flavor for independence\n",
    "explore.chi2_ramen_flavor(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e030651",
   "metadata": {},
   "source": [
    "#### spicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ba0d5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spicy status and five-star ratings have a dependent relationship with 95% confidence.\n",
      "p-value: 0.014\n"
     ]
    }
   ],
   "source": [
    "# create spicy feature\n",
    "train = explore.create_spicy(train)\n",
    "# test spicy for independence\n",
    "explore.chi2_ramen_spicy_status(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ce2a4",
   "metadata": {},
   "source": [
    "#### fried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf346d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fried status and five-star ratings are independent, did not pass 95% confidence interval.\n",
      "p-value: 0.282\n"
     ]
    }
   ],
   "source": [
    "# create fried feature\n",
    "train = explore.create_fried(train)\n",
    "# test fried for independence\n",
    "explore.chi2_ramen_fried_status(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd2b846",
   "metadata": {},
   "source": [
    "### Results of Breaking Down Product Name\n",
    "**Through feature engineering and statistical testing, the features 'flavor' and 'spicy' will join 'country' in our univariate and bivariate analysis.**\n",
    "\n",
    "# Univatiate Look at Our Candidate Features\n",
    "- Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e43338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create histograms here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac1e93",
   "metadata": {},
   "source": [
    "# Each Country and Flavor Into Brackets\n",
    "## Country\n",
    "### Check Total Reviews and Number of Five-Star Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e1ced4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712276fc",
   "metadata": {},
   "source": [
    "### Bracket Countries Based on Proportion of Five-Star Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27ae2e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bracket countries into high-, medium-, and low-proportion five star review brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d7d574",
   "metadata": {},
   "source": [
    "## Flavor\n",
    "### Check Total Reviews and Number of Five-Star Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a56c788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cceb5c7",
   "metadata": {},
   "source": [
    "### Bracket Flavors Based on Proportion of Five-Star Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15f24edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bracket countries into high-, medium-, and low-proportion five star review brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6a71a",
   "metadata": {},
   "source": [
    "## Final Features: Bivariate Look in Terms of Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00238f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize target/non-target charts for each feature here\n",
    "# include exact numbers and proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b6b0f",
   "metadata": {},
   "source": [
    "## Results of Exploration\n",
    "- Features kept for modeling:\n",
    "\n",
    "# <center>Model\n",
    "## Bottom Line Up Front: What I Did for Model\n",
    "- Prepared entire dataset with model features\n",
    "- Chose F1 Score as our main evaluation metric due to prioritizing accuracy in presence of imbalanced classes\n",
    "- Split dataset into Train, Validate, and Test\n",
    "- Applied SMOTE+Tomek resampling to fix the class imbalance in our target for the Train split\n",
    "- Built, fit several classification models and hyperparameter combinations on resampled Train split\n",
    "- Evaluated baseline and all model performances on Validate, chose best model (Logistic Regression)\n",
    "- Chose not to use Grid Search to optimize hyperparameters due to nature of Logistic Regression hyperparameters\n",
    "- Evaluated baseline and best model's ROC Curve AUC\n",
    "- Evaluated baseline and best model on sequestered Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aea3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adf8902a",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Using nothing more than analyzing ramen product names, I was able to build several categorical features that took into account domain knowledge and translation. Some of these keyword-engineering features were statistically related to our target and used in the model. In the end, our predictive model outperformed the baseline on common evaluation metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
